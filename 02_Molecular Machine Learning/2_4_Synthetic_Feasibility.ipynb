{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOx24yJu+7vyUBw+FAwEy9F"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**2.4 Synthetic Feasibility**"
      ],
      "metadata": {
        "id": "kMu2noZK8hzP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOqfd_o98Nci"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"True\"\n",
        "!pip install --pre deepchem\n",
        "!pip install tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "deepchem.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SK_FsenW8dT_",
        "outputId": "3a032233-70e5-4f88-f55c-bffa0a9b3e20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.1.dev'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem as dc\n",
        "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='Raw', splitter=None)\n",
        "molecules = datasets[0].X"
      ],
      "metadata": {
        "id": "479nJUkr8mdZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "import random\n",
        "from deepchem.feat import CircularFingerprint\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_dataset(fingerprints, smiles_lens, ds_size=100000):\n",
        "    \"\"\"\n",
        "    m1: list of np.Array\n",
        "        fingerprints for molecules\n",
        "    m2: list of int\n",
        "        length of a molecules SMILES string\n",
        "\n",
        "    returns:\n",
        "        dc.data.Dataset for input into ScScore Model\n",
        "\n",
        "    Dataset.X\n",
        "        shape is (sample_id, molecule_id, features)\n",
        "    Dataset.y\n",
        "        shape is (sample_id,)\n",
        "        values is 1 if the 0th index molecule is more complex\n",
        "                  0 if the 1st index molecule is more complex\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    all_data = list(zip(fingerprints, smiles_lens))\n",
        "    while len(y) < ds_size:\n",
        "        i1 = random.randrange(0, len(smiles_lens))\n",
        "        i2 = random.randrange(0, len(smiles_lens))\n",
        "        m1 = all_data[i1]\n",
        "        m2 = all_data[i2]\n",
        "        if m1[1] == m2[1]:\n",
        "            continue\n",
        "        if m1[1] > m2[1]:\n",
        "            y.append(1.0)\n",
        "        else:\n",
        "            y.append(0.0)\n",
        "        X.append([m1[0], m2[0]])\n",
        "    return dc.data.NumpyDataset(np.array(X), np.expand_dims(np.array(y), axis=1))"
      ],
      "metadata": {
        "id": "MYzp6Z2j80X6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "molecule_ds = dc.data.NumpyDataset(np.array(molecules))\n",
        "splitter = dc.splits.RandomSplitter()\n",
        "train_mols, test_mols = splitter.train_test_split(molecule_ds)"
      ],
      "metadata": {
        "id": "bflD3xEp80_j"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 1024\n",
        "featurizer = dc.feat.CircularFingerprint(size=n_features, radius=2, chiral=True)\n",
        "train_features = featurizer.featurize(train_mols.X)\n",
        "train_smiles_len = [len(Chem.MolToSmiles(x)) for x in train_mols.X]\n",
        "train_dataset = create_dataset(train_features, train_smiles_len)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GLJuqwC4828y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = dc.models.ScScoreModel(n_features=n_features)\n",
        "model.fit(train_dataset, nb_epoch=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "uKCb08KH84z5",
        "outputId": "508d22de-3803-47d4-8bdd-097cc04cf930"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "`keras.optimizers.legacy` is not supported in Keras 3. When using `tf.keras`, to continue using a `tf.keras.optimizers.legacy` optimizer, you can install the `tf_keras` package (Keras 2) and set the environment variable `TF_USE_LEGACY_KERAS=True` to configure TensorFlow to use `tf_keras` when accessing `tf.keras`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3140928158.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScScoreModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mrecent\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m         return self.fit_generator(\n\u001b[0m\u001b[1;32m    360\u001b[0m             self.default_generator(dataset,\n\u001b[1;32m    361\u001b[0m                                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceCollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_built\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_interval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             manager = tf.train.CheckpointManager(self._checkpoint,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36m_ensure_built\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         self._tf_optimizer = self.optimizer._create_tf_optimizer(\n\u001b[0m\u001b[1;32m    271\u001b[0m             self._global_step)\n\u001b[1;32m    272\u001b[0m         self._checkpoint = tf.train.Checkpoint(optimizer=self._tf_optimizer,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/deepchem/models/optimizers.py\u001b[0m in \u001b[0;36m_create_tf_optimizer\u001b[0;34m(self, global_step)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         return tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate,\n\u001b[0m\u001b[1;32m    227\u001b[0m                                                \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                                \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLegacyOptimizerWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;34m\"`keras.optimizers.legacy` is not supported in Keras 3. When using \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;34m\"`tf.keras`, to continue using a `tf.keras.optimizers.legacy` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: `keras.optimizers.legacy` is not supported in Keras 3. When using `tf.keras`, to continue using a `tf.keras.optimizers.legacy` optimizer, you can install the `tf_keras` package (Keras 2) and set the environment variable `TF_USE_LEGACY_KERAS=True` to configure TensorFlow to use `tf_keras` when accessing `tf.keras`.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ScScoreëª¨ë¸ - ë‘ ë¶„ìë¥¼ ë¹„êµí•˜ë©° í•™ìŠµ\n",
        "\n",
        "SMILESê°€ ë” ê¸¸ìˆ˜ë¡ ë³µì¡í•œ ë¶„ìë¡œ ê°€ì •í•˜ê³  í•™ìŠµ A,Bì¤‘ ì–´ë–¤ê²Œ ë” ë³µì¡í•œ ë¶„ìì¸ê°€\n",
        "\n",
        "ë¶„ìê°€ ì²«ë²ˆì§¸ê°€ ë” ê¸¸ë©´ 1.0 ë‘ë²ˆì§¸ê°€ ë” ê¸¸ë©´ 0.0\n",
        "\n",
        "ì¼ë°˜ì ìœ¼ë¡œ SMILESê°€ ê¸¸ìˆ˜ë¡ êµ¬ì¡°ê°€ ë³µì¡í•¨ -> í•©ì„±ë‚œì´ë„ ì˜¬ë¼ê°"
      ],
      "metadata": {
        "id": "TKPVCHU2Agqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "2pNOS1u386R5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mol_scores = model.predict_mols(test_mols.X)\n",
        "smiles_lengths = [len(Chem.MolToSmiles(x)) for x in test_mols.X]"
      ],
      "metadata": {
        "id": "CXjDqsUc-DLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,16))\n",
        "plt.scatter(smiles_lengths, mol_scores)\n",
        "plt.xlim(0,80)\n",
        "plt.xlabel(\"SMILES length\")\n",
        "plt.ylabel(\"ScScore\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "6hS9z_je_R_Z",
        "outputId": "b85c6464-3c2d-4880-fcbf-ea1dbc026660"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'smiles_lengths' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1239723799.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SMILES length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ScScore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'smiles_lengths' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ’¡ 2.4 Synthetic Feasibility(ScScore)\n",
        "\n",
        "\n",
        "ìƒëŒ€ì  ì„œì—´ í•™ìŠµ: \"ì´ ë¶„ìëŠ” 80ì \" ê°™ì€ ì ˆëŒ€ì  ìˆ˜ì¹˜ê°€ ì•„ë‹ˆë¼, \"Aë³´ë‹¤ Bê°€ ë§Œë“¤ê¸°ì— ë” ë³µì¡í•˜ë‹¤'ëŠ” ì„ í›„ ê´€ê³„ë¥¼ í•™ìŠµì‹œì¼œ ë¶„ì ê°„ì˜ ìƒëŒ€ì  ë‚œì´ë„ ì§€ë„  êµ¬ì¶•í•¨.\n",
        "\n",
        "ë³µì¡ë„ì˜ ë°ì´í„°í™”: ì‹¤ìŠµì—ì„œëŠ” 'SMILES ê¸¸ì´'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì•˜ì§€ë§Œ, í•©ì„± ë‹¨ê³„ ìˆ˜, ì›ë£Œ ê°€ê²©, ë°˜ì‘ ìœ„í—˜ë„ ë“± í”„ë¡œì íŠ¸ ëª©ì ì— ë§ëŠ” 'ë³µì¡ë„'ì˜ ì •ì˜ë¥¼ ëª¨ë¸ì— ì£¼ì…ê°€ëŠ¥\n",
        "\n",
        "í˜„ì‹¤ì  ìŠ¤í¬ë¦¬ë‹: AIê°€ ì„¤ê³„í•œ ìˆ˜ë§Œ ê°œì˜ í›„ë³´ ë¬¼ì§ˆ ì¤‘ ë¬¼ì„±ì€ ì¢‹ì§€ë§Œ ì œì¡°ê°€ ë¶ˆê°€ëŠ¥í•œ ê²ƒì„ ì‚¬ì „ì— ê±¸ëŸ¬ë‚´ì–´, ì‹œê°„ê³¼ ë¹„ìš© ë‚­ë¹„ë¥¼ ë°©ì§€í•¨."
      ],
      "metadata": {
        "id": "PCqL4a6VDVIi"
      }
    }
  ]
}
