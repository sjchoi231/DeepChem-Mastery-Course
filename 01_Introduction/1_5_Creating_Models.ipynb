{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQNvYJMYuZTm0pnaVQ9iha"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**1.5 Creating Models with TensorFlow and PyTorch**\n"
      ],
      "metadata": {
        "id": "bPHYkU0SoimJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBWrbXdLohdD",
        "outputId": "8a45f7c9-e0a8-48ac-925a-7aa8cde73c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.12/dist-packages (2.8.1.dev20260121224927)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.5.3)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from deepchem) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.6.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.14.0)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from deepchem) (1.16.3)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (from deepchem) (2025.9.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->deepchem) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->deepchem) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->deepchem) (2025.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit->deepchem) (11.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->deepchem) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre deepchem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = 'True'\n",
        "!pip install --quiet tf_keras\n",
        "\n",
        "import deepchem as dc\n",
        "import tensorflow as tf\n",
        "\n",
        "keras_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1000, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model = dc.models.KerasModel(keras_model, dc.models.losses.L2Loss())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxVIaj39pJfT",
        "outputId": "ad45cb39-7c1b-4e6b-918f-5e4ae4d43575"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumAmideBonds. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumAtomStereoCenters. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumBridgeheadAtoms. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumHeterocycles. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumSpiroAtoms. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for Phi. Feature removed!\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.12/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.12/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='ECFP', splitter='random')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "model.fit(train_dataset, nb_epoch=50)\n",
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
        "print('test set score:', model.evaluate(test_dataset, [metric]))"
      ],
      "metadata": {
        "id": "gnbYpNj8piy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "pytorch_model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(1024, 1000),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(1000, 1)\n",
        ")\n",
        "model = dc.models.TorchModel(pytorch_model, dc.models.losses.L2Loss())\n",
        "\n",
        "model.fit(train_dataset, nb_epoch=50)\n",
        "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
        "print('test set score:', model.evaluate(test_dataset, [metric]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptg1t7fAqmYr",
        "outputId": "18f2f76c-8607-4d35-b69a-d1148f25f395"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/deepchem/models/torch_models/torch_model.py:455: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  avg_loss = float(avg_loss) / averaged_batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set score: {'pearson_r2_score': 0.9766506777362862}\n",
            "test set score: {'pearson_r2_score': 0.7630153937510498}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras/PyTorchÎ•º deepchemÏúºÎ°ú WrappingÌïòÍ∏∞"
      ],
      "metadata": {
        "id": "j4jLlunkqp7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ClassificationModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(1000, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        y = self.dense1(inputs)\n",
        "        if training:\n",
        "            y = tf.nn.dropout(y, 0.5)\n",
        "        logits = self.dense2(y)\n",
        "        output = tf.nn.sigmoid(logits)\n",
        "        return output, logits\n",
        "\n",
        "keras_model = ClassificationModel()\n",
        "output_types = ['prediction', 'loss']\n",
        "model = dc.models.KerasModel(keras_model, dc.models.losses.SigmoidCrossEntropy(), output_types=output_types)"
      ],
      "metadata": {
        "id": "JTLqws-Kq85t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_bace_classification(feturizer='ECFP', splitter='scaffold')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "model.fit(train_dataset, nb_epoch=100)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
        "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
        "print('test set score:', model.evaluate(test_dataset, [metric]))"
      ],
      "metadata": {
        "id": "s73j3WkkrPHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ClassificationModel, self).__init__()\n",
        "        self.dense1 = torch.nn.Linear(1024, 1000)\n",
        "        self.dense2 = torch.nn.Linear(1000, 1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        y = torch.nn.functional.relu( self.dense1(inputs) )\n",
        "        y = torch.nn.functional.dropout(y, p=0.5, training=self.training)\n",
        "        logits = self.dense2(y)\n",
        "        output = torch.sigmoid(logits)\n",
        "        return output, logits\n",
        "\n",
        "torch_model = ClassificationModel()\n",
        "output_types = ['prediction', 'loss']\n",
        "model = dc.models.TorchModel(torch_model, dc.models.losses.SigmoidCrossEntropy(), output_types=output_types)"
      ],
      "metadata": {
        "id": "An3TufhjrQ8f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_bace_classification(feturizer='ECFP', splitter='scaffold')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "model.fit(train_dataset, nb_epoch=100)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
        "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
        "print('test set score:', model.evaluate(test_dataset, [metric]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClRANDcSrTK1",
        "outputId": "105c0aee-c21a-44e5-a5bb-fe267f91d8dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set score: {'roc_auc_score': 0.9996228260110358}\n",
            "test set score: {'roc_auc_score': 0.764447463768116}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üí° Insight & Reflection\n",
        "\n",
        "Logits ÌôúÏö©: SigmoidCrossEntropy ÏÜêÏã§ Ìï®ÏàòÎ•º ÏÇ¨Ïö©Ìï† Îïå ÌôïÎ•†Í∞íÏù¥ ÏïÑÎãå logitsÎ•º ÏßÅÏ†ë Ï†ÑÎã¨Ìï®ÏúºÎ°úÏç® ÏàòÏπòÏ†Å ÏïàÏ†ïÏÑ±(Numerical Stability)ÏùÑ ÎÜíÏûÑ.\n",
        "\n",
        "Subclassing API: tf.keras.Model ÎòêÎäî torch.nn.ModuleÏùÑ ÏÉÅÏÜçÎ∞õÏïÑ Î™®Îç∏ÏùÑ ÏÑ§Í≥ÑÌï®ÏúºÎ°úÏç®, Îã§Ï§ë Ï∂úÎ†•(Multi-output) Î∞è Ï†ïÍµêÌïú Forward Pass Ï†úÏñ¥Í∞Ä Í∞ÄÎä•Ìï¥Ïßê.\n",
        "\n",
        "Scaffold Split: Murcko Scaffold Í∏∞Ï§ÄÏúºÎ°ú Îã§Î•∏ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Î∂ÑÎ¶¨ÌïòÏó¨ ÌèâÍ∞ÄÌï®ÏúºÎ°úÏç® ÏóÑÍ≤©ÌïòÍ≤å Í≤ÄÏ¶ù"
      ],
      "metadata": {
        "id": "Z1zZ0xRIuhSQ"
      }
    }
  ]
}