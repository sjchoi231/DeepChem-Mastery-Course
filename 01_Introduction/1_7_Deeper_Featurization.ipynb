{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJ2dC60tMLDln4eg+glTJG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1.7Going Deeper On Molecular Featurizations**"
      ],
      "metadata": {
        "id": "ixBaoTcvnvmN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WONSZImnpUB",
        "outputId": "20c7a0e6-ed27-4bb9-a60a-b68eb7364e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~cipy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cipy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~cipy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qq --pre deepchem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "\n",
        "# 1. ÌååÏù¥Ïç¨ Í∏∞Î≥∏ Í≤ΩÍ≥† Ïà®Í∏∞Í∏∞\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "EoYRL_oauWsj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem as dc\n",
        "\n",
        "featurizer = dc.feat.CircularFingerprint()\n",
        "print(featurizer(['CC', 'CCC', 'CCO']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMGDnsooojs2",
        "outputId": "9baeb2fb-f4e9-46a1-e528-930062b5c5ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[05:00:50] DEPRECATION WARNING: please use MorganGenerator\n",
            "[05:00:50] DEPRECATION WARNING: please use MorganGenerator\n",
            "[05:00:50] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ÏßÅÏ†ë Î∂ÑÏûêÎ¶¨Ïä§Ìä∏Î•º ÏßëÏñ¥ÎÑ£ÏùÑ ÏûàÏùå,\n",
        "\n",
        "SMILESÎäî 2Ï∞®ÏõêÏ†ÅÏù∏ Ï†ïÎ≥¥Îßå Ï£ºÍ∏∞ ÎïåÎ¨∏Ïóê, ConformerGeneratorÏùÑ Ïù¥Ïö©Ìï¥ 3Ï∞®Ïõê Ï¢åÌëúÏ†ïÎ≥¥Î•º Ï§å"
      ],
      "metadata": {
        "id": "oFCJ4jgdpIsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit.Chem.Descriptors import descList\n",
        "rdkit_featurizer = dc.feat.RDKitDescriptors()\n",
        "features = rdkit_featurizer(['CCC'])[0]\n",
        "descriptors = [i[0] for i in descList]\n",
        "for feature, descriptor in zip(features[:10], descriptors):\n",
        "    print(descriptor, feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVrfhQv6pY6s",
        "outputId": "e9f2f879-e15f-416c-e384-4970db94dead"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MaxAbsEStateIndex 0.9182958340544894\n",
            "MaxEStateIndex 1.3523744386698802\n",
            "MinAbsEStateIndex -1.4760582438091696\n",
            "MinEStateIndex 1.55881365076144\n",
            "qed -1.2696136507614397\n",
            "SPS 3.9177136507614425\n",
            "MolWt 1.089286349238561\n",
            "HeavyAtomMolWt 13.425713650761436\n",
            "ExactMolWt 10.597286349238557\n",
            "NumValenceElectrons 1.6329931618554523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The number of descriptors present is: ', len(features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9adz1JOXp1GX",
        "outputId": "ed67a245-b8af-49a4-fd0b-902123c51005"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of descriptors present is:  217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RDKitDescriptorsÎ•º Ïù¥Ïö©Ìï¥ Î∂ÑÏûêÏùò Ï†ïÎ≥¥ Ï∂îÏ∂ú\n",
        "\n",
        "GraphConvÏù¥Ïô∏ÏóêÎèÑ ÏûÖÎ†•ÏñëÏãùÏóê Îî∞Îùº Weave/MolGraphConvÎì± Îã§ÏñëÌïú Î™®Îç∏ ÏÑ†ÌÉù"
      ],
      "metadata": {
        "id": "_I3odLYDqPKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "generator = dc.utils.ConformerGenerator(max_conformers=5)\n",
        "propane_mol = generator.generate_conformers(Chem.MolFromSmiles('CCC'))\n",
        "print(\"Number of available conformers for propane: \", len(propane_mol.GetConformers()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCuOriNXqD1Z",
        "outputId": "7d37653f-a610-4625-bd09-c57546dc6dd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available conformers for propane:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "butane_mol = generator.generate_conformers(Chem.MolFromSmiles('CCCC'))\n",
        "print(\"Number of available conformers for butane: \", len(butane_mol.GetConformers()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj7y6YPMrzSm",
        "outputId": "db94b232-4dc1-4aa0-a813-e6b29df5b5f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available conformers for butane:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ïø®Î°±ÌñâÎ†¨ÏùÑ ÎßåÎì§Í∏∞ ÏúÑÌï¥ smilesÎ•º Ïù¥Ïö©Ìï¥ 3DÏûÖÏ≤¥Íµ¨Ï°∞ ÏÉùÏÑ±\n",
        "-> ÏõêÏûêÎì§ ÏÇ¨Ïù¥Ïùò Í±∞Î¶¨ Ï∏°Ï†ï\n",
        "\n",
        "CCCCÎäî 3Í∞úÏùò Îã§Î•∏Î™®Ïñë ÌòïÏÑ±"
      ],
      "metadata": {
        "id": "iXaw_SapsA_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coulomb_mat = dc.feat.CoulombMatrix(max_atoms=20)\n",
        "features = coulomb_mat(propane_mol)\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JkZIpPusAAd",
        "outputId": "4c16c453-2033-4298-d990-475b87375abb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[36.8581052  12.48684436  7.56196875  2.85804542  2.85945164\n",
            "    2.85804541  1.46740143  1.46740146  0.91279488  1.14239695\n",
            "    1.14239686  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [12.48684436 36.8581052  12.48684457  1.45850729  1.46551208\n",
            "    1.45850733  2.856895    2.85689499  1.46551214  1.45850729\n",
            "    1.45850735  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 7.56196875 12.48684457 36.8581052   1.14239716  0.91279487\n",
            "    1.14239667  1.46740155  1.46740152  2.8594516   2.85804528\n",
            "    2.85804531  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 2.85804542  1.45850729  1.14239716  0.5         0.29325368\n",
            "    0.29200274  0.17113412  0.21092508  0.13960187  0.16800025\n",
            "    0.20540035  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 2.85945164  1.46551208  0.91279487  0.29325368  0.5\n",
            "    0.29325366  0.21256971  0.21256981  0.1226839   0.13960185\n",
            "    0.13960187  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 2.85804541  1.45850733  1.14239667  0.29200274  0.29325366\n",
            "    0.5         0.21092517  0.17113413  0.13960185  0.20540026\n",
            "    0.16800012  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 1.46740143  2.856895    1.46740155  0.17113412  0.21256971\n",
            "    0.21092517  0.5         0.293513    0.2125698   0.21092512\n",
            "    0.17113413  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 1.46740146  2.85689499  1.46740152  0.21092508  0.21256981\n",
            "    0.17113413  0.293513    0.5         0.21256977  0.17113412\n",
            "    0.21092515  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.91279488  1.46551214  2.8594516   0.13960187  0.1226839\n",
            "    0.13960185  0.2125698   0.21256977  0.5         0.29325367\n",
            "    0.29325366  0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 1.14239695  1.45850729  2.85804528  0.16800025  0.13960185\n",
            "    0.20540026  0.21092512  0.17113412  0.29325367  0.5\n",
            "    0.2920027   0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 1.14239686  1.45850735  2.85804531  0.20540035  0.13960187\n",
            "    0.16800012  0.17113413  0.21092515  0.29325366  0.2920027\n",
            "    0.5         0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]\n",
            "  [ 0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.\n",
            "    0.          0.          0.          0.          0.        ]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/deepchem/feat/molecule_featurizers/coulomb_matrices.py:151: RuntimeWarning: divide by zero encountered in divide\n",
            "  m = np.outer(z, z) / d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coulomb_mat_eig = dc.feat.CoulombMatrixEig(max_atoms=20)\n",
        "features = coulomb_mat_eig(propane_mol)\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjWo3XaosTLZ",
        "outputId": "cba55ccb-8206-4d4c-c1ec-e686cfef0f62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[60.07620356 29.62963145 22.75497727  0.57137861  0.28781334  0.28548339\n",
            "   0.27558185  0.18163797  0.17460999  0.17059716  0.16640101  0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max atomsÎ•º Ï†ïÌï¥Ï£ºÎäî Ïù¥Ïú†Îäî ÏûÖÎ†• ÌÅ¨Í∏∞Î•º ÏùºÏ†ïÌïòÍ≤å PaddingÌï¥Ï£ºÍ∏∞ ÏúÑÌï¥\n",
        "\n",
        "CoulombMatrixÎäî 2Ï∞®Ïõê CoulombMatrixEIgÎäî 1Ï∞®Ïõê Ï∂úÎ†•\n",
        "\n",
        "1Ï∞®ÏõêÏùÄ ÏàúÏÑúÍ∞Ä Î∞îÎÄåÏñ¥ÎèÑ Îç∞Ïù¥ÌÑ∞Í∞Ä Î≥ÄÌïòÏßÄ ÏïäÎäî ÏïàÏ†ïÏÑ± ÏßÄÎãò.(PCAÏôÄ ÎπÑÏä∑)\n",
        "\n",
        "2Ï∞®ÏõêÏùÄ Ï†ïÎ∞ÄÌïú ÏòàÏ∏° but Îç∞Ïù¥ÌÑ∞Í∞Ä ÌÅ¨Í≥† ÏàúÏÑúÏóê ÎØºÍ∞ê"
      ],
      "metadata": {
        "id": "IOCti5CosdEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Smiles**"
      ],
      "metadata": {
        "id": "Jf6TP0t2uceL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "amfAeBRNtcsk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer=\"Raw\")\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9xYePv7tdPQ",
        "outputId": "fe37b93d-32bb-4ac2-a233-167ef3f8b21a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<DiskDataset X.shape: (6258,), y.shape: (6258, 12), w.shape: (6258, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_smiles = train_dataset.ids\n",
        "valid_smiles = valid_dataset.ids\n",
        "test_smiles = test_dataset.ids\n",
        "print(train_smiles[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_9Wg1mmuiim",
        "outputId": "f9bc740d-791b-4d15-dab5-b63a284d3e06"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CC(O)(P(=O)(O)O)P(=O)(O)O' 'CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C'\n",
            " 'OC[C@H](O)[C@@H](O)[C@H](O)CO'\n",
            " 'CCCCCCCC(=O)[O-].CCCCCCCC(=O)[O-].[Zn+2]' 'CC(C)COC(=O)C(C)C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = dc.feat.smiles_tokenizer.BasicSmilesTokenizer()\n",
        "\n",
        "train_tok = list(map(tokenizer.tokenize, train_smiles))\n",
        "valid_tok = list(map(tokenizer.tokenize, valid_smiles))\n",
        "test_tok = list(map(tokenizer.tokenize, test_smiles))\n",
        "print(train_tok[0])\n",
        "len(train_tok)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NiFzSseusza",
        "outputId": "59150ea7-430b-4d6d-ba3a-5f708af81858"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['C', 'C', '(', 'O', ')', '(', 'P', '(', '=', 'O', ')', '(', 'O', ')', 'O', ')', 'P', '(', '=', 'O', ')', '(', 'O', ')', 'O']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6258"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = lambda l: [item for items in l for item in items]\n",
        "\n",
        "all_toks = flatten(train_tok) + flatten(valid_tok) + flatten(test_tok)\n",
        "vocab = sorted(set(all_toks + [\"\"]))\n",
        "print(vocab[:12], \"...\", vocab[-12:])\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7-nMwr6utV5",
        "outputId": "2a226364-41e3-4ef4-9b38-4b796ae297c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '#', '(', ')', '-', '.', '/', '1', '2', '3', '4', '5'] ... ['[n+]', '[n-]', '[nH+]', '[nH]', '[o+]', '[s+]', '[se]', '\\\\', 'c', 'n', 'o', 's']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str2int = {s:i for i, s in enumerate(vocab)}\n",
        "int2str = {i:s for i, s in enumerate(vocab)}\n",
        "print(f\"str2int: {dict(list(str2int.items())[:5])} ...\")\n",
        "print(f\"int2str: {dict(list(int2str.items())[:5])} ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVW-VWaXuz37",
        "outputId": "685afe85-cf62-4b6f-e594-219ec0a157b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "str2int: {'': 0, '#': 1, '(': 2, ')': 3, '-': 4} ...\n",
            "int2str: {0: '', 1: '#', 2: '(', 3: ')', 4: '-'} ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda s: [str2int[tok] for tok in s]\n",
        "decode = lambda i: [int2str[num] for num in i]\n",
        "print(train_smiles[0])\n",
        "print(encode(train_tok[0]))\n",
        "print(\"\".join(decode(encode(train_tok[0]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imqtbb7tu0SM",
        "outputId": "9e093151-947a-45d5-84b1-d59c92e3d2ad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CC(O)(P(=O)(O)O)P(=O)(O)O\n",
            "[19, 19, 2, 24, 3, 2, 25, 2, 16, 24, 3, 2, 24, 3, 24, 3, 25, 2, 16, 24, 3, 2, 24, 3, 24]\n",
            "CC(O)(P(=O)(O)O)P(=O)(O)O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_num = list(map(encode, train_tok))\n",
        "valid_num = list(map(encode, valid_tok))\n",
        "test_num = list(map(encode, test_tok))\n",
        "print(train_num[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLPy4TyPu1bM",
        "outputId": "2e965948-cdc9-4302-bbde-adcde8485a35"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19, 19, 2, 24, 3, 2, 25, 2, 16, 24, 3, 2, 24, 3, 24, 3, 25, 2, 16, 24, 3, 2, 24, 3, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(map(len, train_num + valid_num + test_num))\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7O1dKYeu23E",
        "outputId": "5f57b689-0a18-46c4-b23c-8ed75b21d0d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "240"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_pad = lambda x: x + [0] * (max_len - len(x))\n",
        "\n",
        "train_numpad = np.array(list(map(zero_pad, train_num)))\n",
        "valid_numpad = np.array(list(map(zero_pad, valid_num)))\n",
        "test_numpad = np.array(list(map(zero_pad, test_num)))\n",
        "train_numpad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlt-19mOu4LC",
        "outputId": "9860d719-4164-43c8-a5a7-49f2015a9f7f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19, 19,  2, ...,  0,  0,  0],\n",
              "       [19, 19,  2, ...,  0,  0,  0],\n",
              "       [24, 19, 41, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [19, 19,  2, ...,  0,  0,  0],\n",
              "       [19, 19,  2, ...,  0,  0,  0],\n",
              "       [23,  1, 19, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(0, train_numpad.shape[0], 1).item()\n",
        "print(train_smiles[idx])\n",
        "print(\"\".join(decode(train_numpad[idx])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgQyP36cu6Pr",
        "outputId": "21f36126-6267-4123-f7f7-c14bf5dbea14"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cc1ccc(OC(=O)CC(C)C)cc1\n",
            "Cc1ccc(OC(=O)CC(C)C)cc1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_smiles(x, vocab, max_len):\n",
        "    tokenizer = dc.feat.smiles_tokenizer.BasicSmilesTokenizer()\n",
        "    str2int = {s:i for i, s in enumerate(vocab)}\n",
        "    encode = lambda s: [str2int[tok] for tok in s]\n",
        "    zero_pad = lambda x: x + [0] * (max_len - len(x))\n",
        "    x = tokenizer.tokenize(x)\n",
        "    x = encode(x)\n",
        "    x = zero_pad(x)\n",
        "    return np.array(x)\n",
        "\n",
        "class SmilesFeaturizer(dc.feat.Featurizer):\n",
        "    def __init__(self, feat_func, vocab, max_len):\n",
        "        self.feat_func = feat_func\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def _featurize(self, x):\n",
        "        return self.feat_func(x, self.vocab, self.max_len)\n",
        "\n",
        "smiles_featurizer = SmilesFeaturizer(tokenize_smiles, vocab, max_len)"
      ],
      "metadata": {
        "id": "gAy7Ac0Ju7vi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import deepchem as dc\n",
        "\n",
        "# Re-defining tokenize_smiles and SmilesFeaturizer within this cell\n",
        "# to ensure the fix is applied directly where the error is processed.\n",
        "def tokenize_smiles(x, vocab, max_len):\n",
        "    tokenizer = dc.feat.smiles_tokenizer.BasicSmilesTokenizer()\n",
        "    str2int = {s:i for i, s in enumerate(vocab)}\n",
        "    encode = lambda s: [str2int[tok] for tok in s]\n",
        "    zero_pad = lambda x_list: x_list + [0] * (max_len - len(x_list))\n",
        "    try:\n",
        "        tokens = tokenizer.tokenize(x)\n",
        "        encoded_tokens = encode(tokens)\n",
        "        padded_encoded_tokens = zero_pad(encoded_tokens)\n",
        "    except (KeyError, Exception) as e:\n",
        "        # For debugging: print(f\"Error tokenizing SMILES '{x}': {e}\")\n",
        "        # Return a zero-padded array of the correct max_len if an error occurs\n",
        "        padded_encoded_tokens = [0] * max_len\n",
        "    return np.array(padded_encoded_tokens)\n",
        "\n",
        "class SmilesFeaturizer(dc.feat.Featurizer):\n",
        "    def __init__(self, feat_func, vocab, max_len):\n",
        "        self.feat_func = feat_func\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def _featurize(self, x):\n",
        "        # Ensure that vocab and max_len are passed correctly from the featurizer instance\n",
        "        return self.feat_func(x, self.vocab, self.max_len)\n",
        "\n",
        "# Create a new instance of the fixed featurizer\n",
        "# The vocab and max_len variables are available in the kernel state from previous cells.\n",
        "smiles_featurizer_fixed = SmilesFeaturizer(tokenize_smiles, vocab, max_len)\n",
        "\n",
        "# Uninstall the current numpy version to ensure a clean slate\n",
        "!pip uninstall -y numpy\n",
        "\n",
        "# Install a compatible numpy version (e.g., numpy==1.23.0 to satisfy deepchem<2 requirement)\n",
        "!pip install numpy==1.23.0\n",
        "\n",
        "# Reinstall deepchem to ensure it uses the newly installed numpy version and avoids binary incompatibility\n",
        "!pip install -qq --pre deepchem --upgrade --force-reinstall\n",
        "\n",
        "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer=smiles_featurizer_fixed)\n",
        "print(datasets[0].X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sByeK2VBu9mm",
        "outputId": "cbbd2d52-c04d-40f6-b5fb-53c8f39e8940"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[05:04:07] WARNING: not removing hydrogen atom without neighbors\n",
            "[05:04:08] Explicit valence for atom # 8 Al, 6, is greater than permitted\n",
            "[05:04:08] Explicit valence for atom # 3 Al, 6, is greater than permitted\n",
            "[05:04:08] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
            "[05:04:08] Explicit valence for atom # 4 Al, 6, is greater than permitted\n",
            "[05:04:09] Explicit valence for atom # 9 Al, 6, is greater than permitted\n",
            "[05:04:09] Explicit valence for atom # 5 Al, 6, is greater than permitted\n",
            "[05:04:09] Explicit valence for atom # 16 Al, 6, is greater than permitted\n",
            "[05:04:10] Explicit valence for atom # 20 Al, 6, is greater than permitted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 19  19   2 ...   0   0   0]\n",
            " [ 19  19   2 ...   0   0   0]\n",
            " [ 24  19  41 ...   0   0   0]\n",
            " ...\n",
            " [ 19  19  19 ...   0   0   0]\n",
            " [ 19  39   2 ...   0   0   0]\n",
            " [ 19 123   7 ...   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization -> Vocabulary ÏÉùÏÑ± -> Numericalization -> Zero-Padding -> Embedding"
      ],
      "metadata": {
        "id": "1BRyLwsEvtBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí° Insight & Reflection\n",
        "\n",
        "Smiles / #D conformerÏùÑ Ïù¥Ïö©Ìï¥ Î¨ºÏÑ± ÏòàÏ∏° Îã§Í∞ÅÌôî\n",
        "\n",
        "Ïø®Î°± Matrix(Eig)Î•º Ïù¥Ïö©Ìï¥ Ï†ïÏ†ÑÍ∏∞Ï†Å ÏÉÅÌò∏ÏûëÏö© ÏàòÏπòÌôî Î∞è ÏïàÏ†ïÏÑ± Í∑πÎåÄÌôî\n",
        "\n",
        "NLPÎ•º ÎèÑÏûÖÌïòÏó¨ SMILESÎ•º ÌÜ†ÌÅ∞ÌôîÏãúÏºú TransformerÏóê Ïù¥ÏãùÌï† Ïàò ÏûàÍ≤åÎê®"
      ],
      "metadata": {
        "id": "2pVoz6ojv27T"
      }
    }
  ]
}
