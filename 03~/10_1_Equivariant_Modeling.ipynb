{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNUu1tjOUvzIBlnMeN7et7p"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **10.1 Introduction To Equivariance and Equivariant Modeling**"
      ],
      "metadata": {
        "id": "p0mmS9XURwYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invariance : 입력은 바꿔도 출력은 그대로 (분자를 90도 회전시켜도 에너지는 동일)\n",
        "\n",
        "Equivariance : 입력을 바꾼만큼 똑같이 변함 (분자를 90도 회전시키면 힘의 방향도 90도 회전)"
      ],
      "metadata": {
        "id": "drYd8YbvR4f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 구조적 정보 보존\n",
        "\n",
        "2. 대칭성과 불변성 처리\n",
        "\n",
        "3. 일반화 능력 향상\n",
        "\n",
        "4. 그래프 구조 데이터 효율적 처"
      ],
      "metadata": {
        "id": "dnE23dSmSYKP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yVKVIEbMRTvH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42) # seed for reproducibility\n",
        "\n",
        "R_i = np.random.rand(12, 3) # 12 atoms with xyz coordinates\n",
        "N = R_i.shape[0] # number of atoms\n",
        "X_i = np.zeros((N, 2)) # feature vectors for the atoms with shape (N, 2)\n",
        "X_i[:4, 0] = 1\n",
        "X_i[4:, 1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hidden_model(r: np.ndarray, x: np.ndarray, w1: np.ndarray, w2: np.ndarray, b1: np.ndarray, b2: float) -> np.ndarray:\n",
        "    r\"\"\"Computes the output of a 1-hidden layer neural network model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        r : np.ndarray\n",
        "            Input array for position values.\n",
        "            Shape: (num_atoms, num_positions)\n",
        "        x : np.ndarray\n",
        "            Input array for features.\n",
        "            Shape: (num_atoms, num_features)\n",
        "        w1 : np.ndarray\n",
        "            Weight matrix for the first layer.\n",
        "            Shape: (num_positions + num_features, hidden_size)\n",
        "        w2 : np.ndarray\n",
        "            Weight matrix for the second layer.\n",
        "            Shape: (hidden_size, output_size)\n",
        "        b1 : np.ndarray\n",
        "            Bias vector for the first layer.\n",
        "            Shape: (hidden_size,)\n",
        "        b2 : float\n",
        "            Bias value for the second layer.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        float\n",
        "            Predicted energy of the molecule\n",
        "    \"\"\"\n",
        "    i = np.concatenate((r, x), axis=1).flatten()  # Stack inputs into one large input\n",
        "    v = np.tanh(i @ w1 + b1)  # Apply activation function to first layer\n",
        "    v = v @ w2 + b2  # Multiply with weights and add bias for the second layer\n",
        "    return v\n",
        "\n",
        "\n",
        "# Initialize weights for a network with hidden size is 16\n",
        "w1 = np.random.normal(size=(N * 5, 16))  # 3(#positions) + 2(#features) = 5\n",
        "b1 = np.random.normal(size=(16,))\n",
        "w2 = np.random.normal(size=(16,))\n",
        "b2 = np.random.normal()"
      ],
      "metadata": {
        "id": "yImEQIbVSsOG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.spatial.transform as transform\n",
        "\n",
        "rotate = transform.Rotation.from_euler(\"x\", 60, degrees=True) # Rotate around x axis by 60 degrees\n",
        "\n",
        "permuted_R_i = np.copy(R_i)\n",
        "permuted_R_i[0], permuted_R_i[1] = R_i[1], R_i[0] # Swap the rows of R_i\n",
        "\n",
        "print(\"without change:\", hidden_model(R_i, X_i, w1, w2, b1, b2))\n",
        "print(\"after permutation:\", hidden_model(permuted_R_i, X_i, w1, w2, b1, b2))\n",
        "print(\"after translation:\", hidden_model(R_i + np.array([3, 3, 3]), X_i, w1, w2, b1, b2))\n",
        "print(\"after rotation:\", hidden_model(rotate.apply(R_i), X_i, w1, w2, b1, b2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxQYu8IOSsyh",
        "outputId": "2b733833-0799-4e00-ec15-c70c1fc5b603"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without change: 4.0914311641808805\n",
            "after permutation: 2.235218761280032\n",
            "after translation: -0.15670614466272625\n",
            "after rotation: 0.5155425905215233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hidden_model_perm(r: np.ndarray, x: np.ndarray, w1: np.ndarray, w2: np.ndarray, b1: np.ndarray, b2: float) -> np.ndarray:\n",
        "    r\"\"\"Computes the output of a 1-hidden layer neural network model with permutation invariance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        r : np.ndarray\n",
        "            Input array for position values.\n",
        "            Shape: (num_atoms, num_positions)\n",
        "        x : np.ndarray\n",
        "            Input array for features.\n",
        "            Shape: (num_atoms, num_features)\n",
        "        w1 : np.ndarray\n",
        "            Weight matrix for the first layer.\n",
        "            Shape: (num_positions + num_features, hidden_size)\n",
        "        w2 : np.ndarray\n",
        "            Weight matrix for the second layer.\n",
        "            Shape: (hidden_size, output_size)\n",
        "        b1 : np.ndarray\n",
        "            Bias vector for the first layer.\n",
        "            Shape: (hidden_size,)\n",
        "        b2 : float\n",
        "            Bias value for the second layer.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        float\n",
        "            Predicted energy of the molecule\n",
        "    \"\"\"\n",
        "    i = np.concatenate((r, x), axis=1)  # Stack inputs into one large input\n",
        "    v = np.tanh(i @ w1 + b1)  # Apply activation function to first layer\n",
        "    v = np.sum(v, axis=0) # Reduce the output by summing across the axis which gives permutational invariance\n",
        "    v = v @ w2 + b2  # Multiply with weights and add bias for the second layer\n",
        "    return v\n",
        "\n",
        "# Initialize weights\n",
        "w1 = np.random.normal(size=(5, 16))\n",
        "b1 = np.random.normal(size=(16,))\n",
        "w2 = np.random.normal(size=(16,))\n",
        "b2 = np.random.normal()"
      ],
      "metadata": {
        "id": "Ibq1fnWMSwn9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"without change:\", hidden_model_perm(R_i, X_i, w1, w2, b1, b2))\n",
        "print(\"after permutation:\", hidden_model_perm(permuted_R_i, X_i, w1, w2, b1, b2))\n",
        "print(\"after translation:\", hidden_model_perm(R_i + np.array([3, 3, 3]), X_i, w1, w2, b1, b2))\n",
        "print(\"after rotation:\", hidden_model_perm(rotate.apply(R_i), X_i, w1, w2, b1, b2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQzdji1qSyE3",
        "outputId": "42cd1df5-946d-42ed-a6f8-ae3e13cf7486"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without change: 63.42865014451651\n",
            "after permutation: 63.42865014451651\n",
            "after translation: 100.6256277697755\n",
            "after rotation: 66.30189546860116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반모델 -> 모든 원자의 좌표와 특징을 하나로 길게 펼쳐서 입력 -> 동일한 분자임에도  순서바꿈(Permutation), 옆으로 옮김(Translation), 회전(Rotation) 하면 예측값 바뀜\n",
        "\n",
        "\n",
        "Permutational Invariance 해결\n",
        "\n",
        "1. 모든 원자에 대해 동일한 가중치 적용해 원자의 특징 먼저 계산\n",
        "\n",
        "2. 그 결과값들을 모두 더함\n",
        "\n",
        "-> 원자의 순서가 바뀌어도 합계는 변하지 않아 불변성 확보\n",
        "\n",
        "\n",
        "But\n",
        "\n",
        "Permutation값은 동일하지만 이동과 회전에 대해서는 달라짐\n",
        "\n",
        "입력값으로 절대좌표(x,y,z)를 사용하고 있기 때문에"
      ],
      "metadata": {
        "id": "JSHeBp1zS145"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hidden_model_permute_translate(r: np.ndarray, x: np.ndarray, w1: np.ndarray, w2: np.ndarray, b1: np.ndarray, b2: float) -> np.ndarray:\n",
        "    r\"\"\"Computes the output of a 1-hidden layer neural network model with permutation and translation invariance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        r : np.ndarray\n",
        "            Input array for position values.\n",
        "            Shape: (num_atoms, num_positions)\n",
        "        x : np.ndarray\n",
        "            Input array for features.\n",
        "            Shape: (num_atoms, num_features)\n",
        "        w1 : np.ndarray\n",
        "            Weight matrix for the first layer.\n",
        "            Shape: (num_positions + num_features, hidden_size)\n",
        "        w2 : np.ndarray\n",
        "            Weight matrix for the second layer.\n",
        "            Shape: (hidden_size, output_size)\n",
        "        b1 : np.ndarray\n",
        "            Bias vector for the first layer.\n",
        "            Shape: (hidden_size,)\n",
        "        b2 : float\n",
        "            Bias value for the second layer.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        float\n",
        "            Predicted energy of the molecule\n",
        "    \"\"\"\n",
        "    d = r - r[:, np.newaxis] # Compute pairwise distances using broadcasting\n",
        "\n",
        "    # Stack inputs into one large input of N x N x 5\n",
        "    # Concatenate doesn't broadcast, so we manually broadcast the Nx2 x matrix\n",
        "    # into N x N x 2\n",
        "    i = np.concatenate((d, np.broadcast_to(x, (d.shape[:-1] + x.shape[-1:]))), axis=-1)\n",
        "    v = np.tanh(i @ w1 + b1)  # Apply activation function to first layer\n",
        "\n",
        "    v = np.sum(v, axis=(0, 1)) # Reduce the output over both axes by summing\n",
        "    v = v @ w2 + b2  # Multiply with weights and add bias for the second layer\n",
        "    return v"
      ],
      "metadata": {
        "id": "MA8wP1YrTdK-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"without change:\", hidden_model_permute_translate(R_i, X_i, w1, w2, b1, b2))\n",
        "print(\"after permutation:\", hidden_model_permute_translate(permuted_R_i, X_i, w1, w2, b1, b2))\n",
        "print(\"after translation:\", hidden_model_permute_translate(R_i + np.array([3, 3, 3]), X_i, w1, w2, b1, b2))\n",
        "print(\"after rotation:\", hidden_model_permute_translate(rotate.apply(R_i), X_i, w1, w2, b1, b2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9lKsTPqTdrA",
        "outputId": "bdb6636c-e688-4929-a195-a1ac3712f9b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without change: 238.78854708962047\n",
            "after permutation: 238.78854708962035\n",
            "after translation: 238.7885470896204\n",
            "after rotation: 262.5920439748347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translational Invariance\n",
        "\n",
        "절대좌표를 쓰면 이동해도 값이 변함 -> 상대적 위치 벡터 계산\n",
        "\n",
        "벡터는 회전하면 방향이 바뀌어 rotation은 여전치 다름"
      ],
      "metadata": {
        "id": "th6kJVMOTrdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hidden_model_permute_translate_rotate(r: np.ndarray, x: np.ndarray, w1: np.ndarray, w2: np.ndarray, b1: np.ndarray, b2: float) -> np.ndarray:\n",
        "    r\"\"\"Computes the output of a 1-hidden layer neural network model with permutation, translation, and rotation invariance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        r : np.ndarray\n",
        "            Input array for position values.\n",
        "            Shape: (num_atoms, num_positions)\n",
        "        x : np.ndarray\n",
        "            Input array for features.\n",
        "            Shape: (num_atoms, num_features)\n",
        "        w1 : np.ndarray\n",
        "            Weight matrix for the first layer.\n",
        "            Shape: (num_positions, hidden_size)\n",
        "        w2 : np.ndarray\n",
        "            Weight matrix for the second layer.\n",
        "            Shape: (hidden_size, output_size)\n",
        "        b1 : np.ndarray\n",
        "            Bias vector for the first layer.\n",
        "            Shape: (hidden_size,)\n",
        "        b2 : float\n",
        "            Bias value for the second layer.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        float\n",
        "            Predicted energy of the molecule\n",
        "    \"\"\"\n",
        "    # Compute pairwise distances using broadcasting\n",
        "    d = r - r[:, np.newaxis]\n",
        "    # Compute squared distances\n",
        "    d2 = np.sum(d**2, axis=-1, keepdims=True)\n",
        "\n",
        "    # Stack inputs into one large input of N x N x 3\n",
        "    # Concatenate doesn't broadcast, so we manually broadcast the Nx2 x matrix\n",
        "    # into N x N x 2\n",
        "    i = np.concatenate((d2, np.broadcast_to(x, (d2.shape[:-1] + x.shape[-1:]))), axis=-1)\n",
        "    v = np.tanh(i @ w1 + b1)  # Apply activation function to first layer\n",
        "\n",
        "    # Reduce the output over both axes by summing\n",
        "    v = np.sum(v, axis=(0, 1))\n",
        "\n",
        "    v = v @ w2 + b2  # Multiply with weights and add bias for the second layer\n",
        "    return v\n",
        "\n",
        "# Initialize weights\n",
        "w1 = np.random.normal(size=(3, 16))\n",
        "b1 = np.random.normal(size=(16,))\n",
        "w2 = np.random.normal(size=(16,))\n",
        "b2 = np.random.normal()"
      ],
      "metadata": {
        "id": "uAy3gtd4Tft_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"without change:\", hidden_model_permute_translate_rotate(R_i, X_i, w1, w2, b1, b2))\n",
        "print(\"after permutation:\", hidden_model_permute_translate_rotate(permuted_R_i, X_i, w1, w2, b1, b2))\n",
        "print(\"after translation:\", hidden_model_permute_translate_rotate(R_i + np.array([3, 3, 3]), X_i, w1, w2, b1, b2))\n",
        "print(\"after rotation:\", hidden_model_permute_translate_rotate(rotate.apply(R_i), X_i, w1, w2, b1, b2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uth6cYBiTiIn",
        "outputId": "9028bd72-00ec-4371-f8a2-ec6b6ec73ed1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without change: 654.3040623148685\n",
            "after permutation: 654.3040623148685\n",
            "after translation: 654.3040623148685\n",
            "after rotation: 654.3040623148685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rotational Invariance\n",
        "\n",
        "벡터는 회전하면 숫자 바뀜, 에너지는 스칼라 값이므로 회전해도 일정\n",
        "\n",
        "상대적 위치 벡터의 제공거리(d^2) 이용\n",
        "\n",
        "벡터의 길이는 분자를 rotation해도 변하지 않음 -> rotation후에도 일치"
      ],
      "metadata": {
        "id": "kR_KLh8XT62K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "💡Insight\n",
        "\n",
        "절대 좌표로 순서 불변성 확\n",
        "\n",
        "상대 좌표로 이동 불변성 확보\n",
        "\n",
        "거리 행렬을 통해 회전 불변성 구현"
      ],
      "metadata": {
        "id": "O0imQpCFUV4o"
      }
    }
  ]
}